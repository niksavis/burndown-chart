"""
Comprehensive Help Content for Progressive Disclosure Help System

This module stores detailed help content for the help system modals and dialogs.
Content provides comprehensive explanations that complement the concise tooltips.

Content is organized by category to match the original help text structure.
"""

# FORECAST HELP CONTENT - Comprehensive explanations for help pages
FORECAST_HELP_DETAILED = {
    "pert_methodology": """
        PERT (Program Evaluation and Review Technique) uses three-point estimation for probabilistic forecasting:
        
        üìä **Formula Components:**
        ‚Ä¢ Optimistic (O): Best-case scenario from top velocity periods
        ‚Ä¢ Most Likely (ML): Current average velocity from recent data
        ‚Ä¢ Pessimistic (P): Worst-case scenario from lowest velocity periods
        ‚Ä¢ Expected (E): Weighted average = (O + 4√óML + P) √∑ 6
        
        üî¢ **Mathematical Foundation:**
        The formula weights the Most Likely estimate 4x more heavily than extreme scenarios,
        following beta distribution principles for realistic project estimation.
        
        üìà **Confidence Intervals:**
        Uncertainty range calculated as ¬±25% of variance between scenarios.
        Wider ranges indicate higher uncertainty; narrower ranges show more predictable velocity.
    """,
    "optimistic_forecast": """
        Best-case completion estimate based on your highest velocity periods.
        
        Calculated using the top performing periods from your historical data.
        This represents what's possible if everything goes well and velocity improves.
    """,
    "most_likely_forecast": """
        Most probable completion estimate based on current average velocity.
        
        Uses the mathematical average of your recent velocity data points.
        This is typically the most reliable single-point estimate.
    """,
    "pessimistic_forecast": """
        Worst-case completion estimate based on your lowest velocity periods.
        
        Calculated using the poorest performing periods from your historical data.
        This helps identify risks and plan for potential delays.
    """,
    "expected_forecast": """
        PERT Expected estimate using weighted average of all three scenarios.
        
        üî¢ **Step-by-Step Calculation:**
        1. Expected = (Optimistic + 4√óMost Likely + Pessimistic) √∑ 6
        2. Example: (8 + 4√ó12 + 20) √∑ 6 = (8 + 48 + 20) √∑ 6 = 76 √∑ 6 = 12.67 weeks
        
        üìä **Why This Formula:**
        ‚Ä¢ Weights Most Likely 4x more than extremes (follows beta distribution)
        ‚Ä¢ Balances optimism with realism for statistically sound estimates
        ‚Ä¢ Reduces impact of outlier scenarios while acknowledging uncertainty
        
        üí° **Interpretation:** Most reliable single-point forecast for project planning.
    """,
    "three_point_estimation": """
        Three-point estimation technique provides forecast ranges instead of single points.
        
        üéØ **Mathematical Advantage:**
        Single estimates ignore uncertainty; ranges acknowledge project variability.
        
        üìà **Confidence Calculation:**
        Uncertainty bands calculated from variance between optimistic and pessimistic scenarios.
        Wider bands = higher uncertainty, narrower bands = more predictable outcomes.
        
        üîç **Practical Application:**
        Use ranges for risk planning, resource allocation, and stakeholder communication.
        The expected value provides planning target while ranges show risk boundaries.
    """,
    "project_overview": """
        Project Overview provides a comprehensive dashboard of your project's current state and progress metrics.
        
        üìä **Progress Tracking:**
        ‚Ä¢ Items Completion: Shows percentage of work items completed vs remaining
        ‚Ä¢ Points Completion: Shows percentage of story points completed vs remaining
        ‚Ä¢ Timeline Progress: Visual representation of project advancement
        
        üéØ **Key Metrics Displayed:**
        ‚Ä¢ Total project scope (items and points)
        ‚Ä¢ Completed work (items and points) 
        ‚Ä¢ Remaining work estimates
        ‚Ä¢ Completion percentages for both items and points
        
        üìà **Visual Indicators:**
        Progress bars provide immediate visual feedback on project completion status.
        Different completion rates for items vs points can indicate scope or estimation changes.
        
        üí° **Interpretation Guide:**
        Items and points completion percentages may differ due to:
        ‚Ä¢ Variable item complexity (some items worth more points)
        ‚Ä¢ Scope changes affecting total estimates
        ‚Ä¢ Estimation refinements during development
    """,
    "forecast_graph_overview": """
        Interactive forecast visualization showing project completion timeline with uncertainty ranges.
        
        üìà **Chart Elements:**
        ‚Ä¢ Historical Data: Solid lines showing actual completed work over time
        ‚Ä¢ PERT Forecasts: Dashed lines showing three-point estimation projections
        ‚Ä¢ Confidence Bands: Shaded areas indicating forecast uncertainty ranges
        ‚Ä¢ Scope Changes: Vertical markers showing requirement additions
        
        üî¢ **PERT Integration:**
        The chart displays all three PERT scenarios:
        ‚Ä¢ Optimistic: Best-case completion timeline (green)
        ‚Ä¢ Most Likely: Expected completion timeline (blue) 
        ‚Ä¢ Pessimistic: Worst-case completion timeline (red)
        ‚Ä¢ Expected: Weighted PERT calculation (primary forecast)
        
        üìä **Burndown Chart:**
        ‚Ä¢ Shows remaining work decreasing toward zero over time
        ‚Ä¢ Ideal for tracking progress against fixed deadlines
        ‚Ä¢ Visual representation of project velocity and completion trends
        
        üéØ **Practical Usage:**
        ‚Ä¢ Use for stakeholder communication and deadline planning
        ‚Ä¢ Monitor actual progress against forecasted timelines
        ‚Ä¢ Identify trends and potential delays early
        ‚Ä¢ Understand impact of scope changes on delivery dates
    """,
    "pert_analysis_detailed": """
        Comprehensive PERT (Program Evaluation and Review Technique) analysis using statistical forecasting.
        
        üî¢ **Three-Point Calculation Method:**
        
        **Data Collection Process:**
        ‚Ä¢ Optimistic (O): Average of top 25% velocity periods from your historical data
        ‚Ä¢ Most Likely (ML): Simple arithmetic mean of all recent data points (typically 8-12 weeks)
        ‚Ä¢ Pessimistic (P): Average of bottom 25% velocity periods from your historical data
        
        **Expected Value Formula:**
        ```
        Expected = (O + 4√óML + P) √∑ 6
        ```
        
        **Interactive Example with Your Project Data:**
        Let's say your recent velocity data shows:
        ‚Ä¢ Best weeks averaged: 15 items/week (optimistic scenario)
        ‚Ä¢ Recent average: 10 items/week (most likely scenario) 
        ‚Ä¢ Worst weeks averaged: 6 items/week (pessimistic scenario)
        
        **Step-by-Step Calculation:**
        ```
        Expected = (15 + 4√ó10 + 6) √∑ 6
        Expected = (15 + 40 + 6) √∑ 6  
        Expected = 61 √∑ 6 = 10.17 items/week
        ```
        
        **Your Completion Timeline:**
        With 50 remaining items: 50 √∑ 10.17 = ~5 weeks expected completion
        
        üìä **Statistical Foundation:**
        ‚Ä¢ **Beta Distribution**: Mathematically models project uncertainty patterns naturally
        ‚Ä¢ **4√ó Most Likely Weighting**: Statistically optimal balance (proven by decades of project data)
        ‚Ä¢ **Confidence Intervals**: ¬±25% of (Optimistic - Pessimistic) variance provides 68% confidence range
        
        üîó **Related Topics:**
        See also: Weekly Velocity Calculation, Forecast Graph Overview, Input Parameters Guide
        
        üéØ **Forecast Applications:**
        ‚Ä¢ Timeline Planning: Use Expected value for primary planning
        ‚Ä¢ Risk Assessment: Monitor gap between Optimistic and Pessimistic
        ‚Ä¢ Stakeholder Communication: Present ranges rather than single dates
        ‚Ä¢ Buffer Planning: Use Pessimistic scenario for contingency planning
        
        üìà **Accuracy Factors:**
        Forecast accuracy improves with:
        ‚Ä¢ More historical data points (8+ weeks recommended)
        ‚Ä¢ Consistent team composition and working patterns
        ‚Ä¢ Stable definition of "done" and estimation practices
        ‚Ä¢ Regular, complete data collection without gaps
    """,
    "input_parameters_guide": """
        Input Parameters control forecast calculations and scope definitions for your project.
        
        üîß **Parameter Relationships:**
        
        **PERT Factor (Default: 6):**
        ‚Ä¢ Controls forecast horizon (number of data points)
        ‚Ä¢ Higher values = more conservative forecasts using more historical data
        ‚Ä¢ Lower values = more responsive forecasts using recent trends
        ‚Ä¢ Range: 2-15 based on project stability needs
        
        **Data Points Count:**
        ‚Ä¢ Number of weeks of historical data to include
        ‚Ä¢ Minimum: 4-6 weeks for basic trends
        ‚Ä¢ Recommended: 8-12 weeks for reliable forecasts
        ‚Ä¢ Maximum: 20+ weeks for very stable long-term projects
        
        **Scope Parameters:**
        ‚Ä¢ Total Items: Complete project scope (all work items)
        ‚Ä¢ Estimated Items: Remaining work items to complete
        ‚Ä¢ Total Points: Complete project effort (all story points)
        ‚Ä¢ Estimated Points: Remaining effort to complete
        
        ‚ö†Ô∏è **Critical Relationships:**
        ‚Ä¢ Estimated values should be ‚â§ Total values
        ‚Ä¢ Changes affect all forecast calculations immediately
        ‚Ä¢ Points-based forecasts often more accurate than item-based
        ‚Ä¢ Regular updates improve forecast accuracy over time
        
        üéØ **Optimization Tips:**
        ‚Ä¢ Increase PERT Factor for volatile teams (new teams, changing scope)
        ‚Ä¢ Decrease PERT Factor for stable teams with consistent delivery
        ‚Ä¢ Update scope parameters weekly as requirements evolve
        ‚Ä¢ Monitor forecast accuracy and adjust parameters accordingly
        
        üìä **Impact on Forecasting:**
        These parameters directly affect:
        ‚Ä¢ PERT calculation timeframes and confidence ranges
        ‚Ä¢ Velocity trend analysis and weighting
        ‚Ä¢ Scope change detection and adaptability metrics
        ‚Ä¢ Weekly forecast generation and accuracy
    """,
}

# VELOCITY HELP CONTENT - Comprehensive explanations for help pages
VELOCITY_HELP_DETAILED = {
    "weekly_velocity_calculation": """
        Weekly velocity represents your team's average completion rate calculated over the last 10 weeks of data.
        
        üìä **Calculation Methods:**
        ‚Ä¢ Average Velocity: Simple arithmetic mean (sum √∑ count)
        ‚Ä¢ Median Velocity: Middle value when sorted (outlier resistant)
        ‚Ä¢ Weighted Average: Recent weeks weighted more heavily
        
        üî¢ **Mathematical Examples:**
        Average: (12 + 15 + 8 + 18 + 10) √∑ 5 = 12.6 items/week
        Median: Sort [8, 10, 12, 15, 18], middle value = 12 items/week
        
        üìà **Trend Analysis:**
        Trend indicators show percentage change from previous periods:
        ‚Ä¢ Up arrows: Velocity acceleration (positive trend)
        ‚Ä¢ Down arrows: Velocity deceleration (negative trend)  
        ‚Ä¢ Stable indicators: Consistent velocity patterns (¬±5% variation)
    """,
    "velocity_trend_indicators": """
        Visual indicators showing velocity change patterns over time.
        
        üéØ **Trend Calculation:**
        Percentage change = ((Current Period - Previous Period) √∑ Previous Period) √ó 100%
        
        üìä **Visual Meanings:**
        ‚Ä¢ üî∫ Green Up Arrow: >5% improvement (acceleration)
        ‚Ä¢ üîª Red Down Arrow: >5% decline (deceleration)
        ‚Ä¢ ‚û°Ô∏è Gray Stable: ¬±5% variation (consistent)
        
        üí° **Interpretation Guide:**
        Consistent upward trends may indicate team learning or process improvements.
        Consistent downward trends may indicate technical debt, scope creep, or team changes.
        Stable trends indicate predictable delivery capacity.
    """,
    "data_quality_impact": """
        Data quality and quantity directly affect forecast accuracy and confidence levels.
        
        üìà **Data Point Requirements:**
        ‚Ä¢ Minimum: 4-6 weeks for basic trends
        ‚Ä¢ Recommended: 8-12 weeks for reliable forecasts
        ‚Ä¢ Optimal: 12+ weeks for high-confidence predictions
        
        üéØ **Quality Factors:**
        ‚Ä¢ Consistency: Regular data collection intervals
        ‚Ä¢ Completeness: No missing weeks or partial data
        ‚Ä¢ Accuracy: Reflects actual work completed (not started)
        ‚Ä¢ Context: Accounts for holidays, team changes, scope shifts
        
        üìä **Impact on Forecasts:**
        More data points = narrower confidence intervals = more reliable predictions
        Less data points = wider confidence intervals = higher uncertainty ranges
    """,
    "velocity_average_calculation": """
        Average Velocity calculation using arithmetic mean for consistent baseline forecasting.
        
        üî¢ **Mathematical Formula:**
        ```
        Average Velocity = Œ£(completed items/points) √∑ Number of weeks
        ```
        
        **Interactive Calculation with Your Data:**
        Let's walk through a realistic example using 5 weeks of project data:
        ‚Ä¢ Week 1: 12 items (normal sprint)
        ‚Ä¢ Week 2: 15 items (good momentum week)  
        ‚Ä¢ Week 3: 8 items (holiday week, reduced capacity)
        ‚Ä¢ Week 4: 18 items (excellent focus week)
        ‚Ä¢ Week 5: 10 items (mixed priorities week)
        
        **Step-by-Step Calculation:**
        ```
        Sum = 12 + 15 + 8 + 18 + 10 = 63 total items
        Weeks = 5 weeks of data
        Average = 63 √∑ 5 = 12.6 items/week
        ```
        
        **Real Forecasting Application:**
        With 50 remaining items: 50 √∑ 12.6 = ~4 weeks expected completion
        
        üìä **Statistical Characteristics:**
        ‚Ä¢ **Equal Weighting**: Every week contributes equally to final calculation
        ‚Ä¢ **Outlier Sensitivity**: Week 4 (18 items) and Week 3 (8 items) both pull the average 
        ‚Ä¢ **Stability Indicator**: Consistent averages = predictable delivery capacity
        ‚Ä¢ **Trending Capability**: Shows velocity evolution over rolling time periods
        
        üìà **Advanced Trend Analysis:**
        ```
        Trend % = ((Current Period - Previous Period) √∑ Previous Period) √ó 100%
        ```
        
        **Practical Trend Example:**
        ‚Ä¢ Previous 5-week average: 10.2 items/week
        ‚Ä¢ Current 5-week average: 12.6 items/week
        ‚Ä¢ Calculation: ((12.6 - 10.2) √∑ 10.2) √ó 100% = +23.5% 
        ‚Ä¢ Interpretation: ‚ÜóÔ∏è **Positive acceleration** - team improving over time
        
        üéØ **Integration with PERT Forecasting:**
        ‚Ä¢ Average velocity = "Most Likely" scenario in three-point estimation
        ‚Ä¢ Provides statistical foundation for expected completion dates
        ‚Ä¢ Combined with optimistic/pessimistic bounds for full PERT analysis
        
        ‚öôÔ∏è **When to Use Average vs Median:**
        ‚Ä¢ **Choose Average** for stable teams with consistent delivery patterns
        ‚Ä¢ **Choose Median** when dealing with frequent scope changes or capacity variations
        
        üîó **Related Topics:**
        See also: Median Velocity Calculation, PERT Analysis Detailed, Velocity Trend Indicators
    """,
    "velocity_median_calculation": """
        Median Velocity calculation using middle value for outlier-resistant forecasting.
        
        üî¢ **Formula:**
        Median Velocity = Middle value when all weekly velocities are sorted
        
        **Step-by-Step Example:**
        Weekly velocities: 12, 15, 8, 18, 10 items
        
        Calculation:
        ‚Ä¢ Sort values: [8, 10, 12, 15, 18]
        ‚Ä¢ Count: 5 values (odd number)
        ‚Ä¢ Median: Middle value = 12 items/week
        
        **Even Number Example:**
        Weekly velocities: 8, 10, 12, 15 items (4 weeks)
        ‚Ä¢ Sort values: [8, 10, 12, 15]
        ‚Ä¢ Median: (10 + 12) √∑ 2 = 11 items/week
        
        üìä **Characteristics:**
        ‚Ä¢ **Outlier Resistance**: High - extreme values don't affect result
        ‚Ä¢ **Stability**: More stable than average when data has outliers
        ‚Ä¢ **Use Case**: Best for teams with variable delivery or scope changes
        ‚Ä¢ **Interpretation**: Represents "typical" week performance
        
        üìà **Advantage Over Average:**
        
        **Example with Outlier:**
        Weekly data: [2, 10, 12, 13, 48] items
        ‚Ä¢ Average: (2+10+12+13+48) √∑ 5 = 17 items/week
        ‚Ä¢ Median: 12 items/week (middle value)
        
        The median (12) better represents typical performance than average (17) 
        which is skewed by the outlier week of 48 items.
        
        üéØ **Forecasting Application:**
        Median velocity provides more realistic estimates when:
        ‚Ä¢ Team has inconsistent delivery patterns
        ‚Ä¢ Data includes exceptional weeks (holidays, crunch periods, blockers)
        ‚Ä¢ Scope changes create velocity variations
        ‚Ä¢ New team members joining/leaving affect capacity
    """,
}

# SCOPE HELP CONTENT - Comprehensive explanations for help pages
SCOPE_HELP_DETAILED = {
    "scope_change_methodology": """
        Scope change rate measures the percentage increase in project requirements relative to the original baseline.
        
        üî¢ **Calculation Formula:**
        Scope Change Rate = (Items Created √∑ Baseline Items) √ó 100%
        
        üìä **Example Calculation:**
        ‚Ä¢ Original baseline: 100 items
        ‚Ä¢ Items added during project: 25 items
        ‚Ä¢ Scope change rate: (25 √∑ 100) √ó 100% = 25%
        
        üéØ **Agile Context:**
        In agile projects, scope changes are normal and healthy, representing:
        ‚Ä¢ Discovery of new requirements
        ‚Ä¢ User feedback integration  
        ‚Ä¢ Market responsiveness
        ‚Ä¢ Learning and adaptation
        
        üìà **Healthy Ranges:**
        ‚Ä¢ 10-30%: Good adaptability without excessive thrash
        ‚Ä¢ 30-50%: High responsiveness, monitor for scope creep
        ‚Ä¢ >50%: Potential planning or requirements issues
    """,
    "adaptability_index": """
        Adaptability Index measures how well your team balances scope changes with delivery consistency.
        
        üî¢ **Calculation Method:**
        Adaptability = 1 - (Standard Deviation of Weekly Scope Changes √∑ Mean Weekly Scope Changes)
        
        üìä **Interpretation Scale:**
        ‚Ä¢ 0.8-1.0: Highly adaptable (excellent scope management)
        ‚Ä¢ 0.5-0.8: Good adaptability (normal agile patterns)
        ‚Ä¢ 0.2-0.5: Moderate adaptability (some instability)
        ‚Ä¢ 0.0-0.2: Low adaptability (high scope volatility)
        
        üéØ **Agile Context:**
        Low values (0.2-0.5) are NORMAL for responsive agile teams!
        This indicates healthy adaptation to changing requirements.
        Very high values might suggest insufficient customer feedback or market responsiveness.
        
        üí° **Action Insights:**
        Use trends over time rather than absolute values for decision making.
    """,
    "throughput_ratio": """
        Throughput ratio compares the rate of new work creation to work completion.
        
        üî¢ **Calculation Formula:**
        Throughput Ratio = Created Items √∑ Completed Items
        
        üìä **Ratio Interpretation:**
        ‚Ä¢ 1.0: Perfect balance (creating = completing)
        ‚Ä¢ <1.0: Burning down backlog (completing > creating)
        ‚Ä¢ >1.0: Growing backlog (creating > completing)
        
        üéØ **Healthy Patterns:**
        ‚Ä¢ Early project: >1.0 (discovery and planning phase)
        ‚Ä¢ Mid project: ~1.0 (steady state development)
        ‚Ä¢ Late project: <1.0 (completion and cleanup phase)
        
        üìà **Strategic Insights:**
        Sustained ratios >1.5 may indicate:
        ‚Ä¢ Insufficient development capacity
        ‚Ä¢ Scope creep or poor requirements management
        ‚Ä¢ Need for capacity planning or priority refinement
    """,
}

# STATISTICS HELP CONTENT - Comprehensive explanations for help pages
STATISTICS_HELP_DETAILED = {
    "data_collection_methodology": """
        Data collection methodology for accurate project tracking and forecasting.
        
        üìÖ **Weekly Data Collection:**
        ‚Ä¢ Collection Point: End of each work week (typically Friday)
        ‚Ä¢ Scope: Monday-Sunday work period for consistency
        ‚Ä¢ Frequency: Weekly snapshots for trend analysis
        
        üî¢ **Data Fields Explained:**
        
        **Week Start (Monday)**: 
        - Date marking the beginning of the work week
        - Used as the reference point for all weekly measurements
        - Should be actual Monday date even if work starts Tuesday
        
        **Items Done This Week**:
        - Count of work items completed during the weekly period
        - Must be truly "done" items that deliver value to users
        - Incremental value (not cumulative) for proper trend analysis
        
        **Points Done This Week**:
        - Story points or effort units completed during the weekly period
        - Should match the point values of items marked as done
        - Incremental value for accurate velocity calculations
        
        **New Items Added**:
        - Count of new work items discovered or added to backlog
        - Includes user stories, bugs, technical tasks, scope additions
        - Tracks scope growth and requirement discovery patterns
        
        **New Points Added**:
        - Point estimate for newly added work items
        - Represents effort impact of scope changes
        - Used for scope change rate and throughput ratio calculations
    """,
    "data_quality_guidelines": """
        Guidelines for maintaining high-quality project data for accurate forecasting.
        
        ‚úÖ **Data Quality Checklist:**
        
        **Completeness:**
        ‚Ä¢ No missing weeks in the data series
        ‚Ä¢ All required fields populated for each week
        ‚Ä¢ Consistent data collection schedule
        
        **Accuracy:**
        ‚Ä¢ Items marked "done" are truly complete and deliverable
        ‚Ä¢ Point estimates reflect actual effort, not initial estimates
        ‚Ä¢ Scope additions captured when decisions are made, not retroactively
        
        **Consistency:**
        ‚Ä¢ Same definition of "done" applied throughout project
        ‚Ä¢ Consistent point estimation approach across the team
        ‚Ä¢ Regular weekly collection schedule maintained
        
        **Context:**
        ‚Ä¢ Document significant events (holidays, team changes, major scope shifts)
        ‚Ä¢ Note any data collection irregularities or exceptions
        ‚Ä¢ Track external factors that might affect velocity patterns
        
        üìä **Impact on Forecasting:**
        High-quality data leads to:
        ‚Ä¢ More accurate PERT forecasts
        ‚Ä¢ Narrower confidence intervals
        ‚Ä¢ Better trend detection
        ‚Ä¢ More reliable completion predictions
        
        Poor data quality results in:
        ‚Ä¢ Wide uncertainty ranges
        ‚Ä¢ Unreliable forecasts
        ‚Ä¢ Missed trend signals
        ‚Ä¢ Reduced stakeholder confidence
    """,
    "weekly_progress_data_explanation": """
        Weekly Progress Data table provides comprehensive tracking of team velocity and scope changes.
        
        üìä **Table Structure:**
        Each row represents one week of project activity with key metrics for forecasting.
        
        üî¢ **Column Definitions:**
        
        **Week Start (Monday):**
        ‚Ä¢ Reference date for the work week (Monday-Sunday period)
        ‚Ä¢ Used for chronological sorting and trend analysis
        ‚Ä¢ Should be actual calendar Monday even if team starts different day
        
        **Items Done This Week:**
        ‚Ä¢ Count of work items completed during this specific week
        ‚Ä¢ Must be truly "done" items (passed testing, deployed, delivered)
        ‚Ä¢ Incremental count (not cumulative total)
        ‚Ä¢ Used for velocity trend analysis and PERT calculations
        
        **Points Done This Week:**
        ‚Ä¢ Story points or effort units completed during this specific week
        ‚Ä¢ Should match the estimated effort of items marked done
        ‚Ä¢ Incremental points (not cumulative total)
        ‚Ä¢ More accurate than item count for teams with variable item complexity
        
        **New Items Added:**
        ‚Ä¢ Work items discovered, created, or added to backlog this week
        ‚Ä¢ Includes user stories, bugs, technical debt, scope additions
        ‚Ä¢ Tracks scope growth and requirement discovery patterns
        ‚Ä¢ Used for scope change rate and adaptability calculations
        
        **New Points Added:**
        ‚Ä¢ Estimated effort for newly added work items
        ‚Ä¢ Represents scope impact of new requirements
        ‚Ä¢ Used for throughput ratio and scope stability analysis
        
        üìà **Usage for Forecasting:**
        
        **Velocity Calculations:**
        ‚Ä¢ Average: Sum of "Items/Points Done" √∑ Number of weeks
        ‚Ä¢ Trend analysis: Percentage change between recent periods
        ‚Ä¢ PERT scenarios: Best/worst/typical performance identification
        
        **Scope Analysis:**
        ‚Ä¢ Growth rate: New items/points added vs baseline scope
        ‚Ä¢ Throughput ratio: Created vs completed work comparison
        ‚Ä¢ Adaptability index: Consistency of scope change patterns
        
        **Data Quality Tips:**
        ‚Ä¢ Enter data weekly for accurate trend detection
        ‚Ä¢ Use consistent "done" definition throughout project
        ‚Ä¢ Include all work types (features, bugs, technical tasks)
        ‚Ä¢ Estimate new items promptly for accurate scope tracking
        
        ‚ö†Ô∏è **Common Mistakes:**
        ‚Ä¢ Entering cumulative totals instead of weekly increments
        ‚Ä¢ Inconsistent item/point estimation practices
        ‚Ä¢ Missing weeks creating gaps in trend analysis
        ‚Ä¢ Different "done" definitions across team members
    """,
}

# CHART HELP CONTENT - Comprehensive explanations for help pages
CHART_HELP_DETAILED = {
    "burndown_chart": """
        Comprehensive guide to interpreting burndown charts for project tracking.
        
        üìâ **Burndown Charts:**
        ‚Ä¢ Show remaining work decreasing over time
        ‚Ä¢ Start high (total scope) and trend toward zero
        ‚Ä¢ Ideal for tracking progress against fixed deadlines
        ‚Ä¢ Emphasize completion progress and deadline tracking
        
        üéØ **Best Practices:**
        ‚Ä¢ Monitor actual progress against forecasted timelines
        ‚Ä¢ Track "how much work is left" to completion
        ‚Ä¢ Identify trends and potential delays early
        ‚Ä¢ Communicate project status to stakeholders
        
        üìä **Visual Elements:**
        ‚Ä¢ Solid lines: Historical actual data
        ‚Ä¢ Dashed lines: PERT forecast projections  
        ‚Ä¢ Dotted lines: Confidence intervals and uncertainty ranges
        ‚Ä¢ Vertical line: Current date marker
        ‚Ä¢ Scope change indicators: Show requirement additions/removals
    """,
    "pert_forecast_methodology": """
        PERT (Program Evaluation Review Technique) creates realistic forecasts using three-point estimation.
        
        üî¢ **Three-Point Estimation Process:**
        1. **Optimistic Scenario**: Best-case timeline from peak velocity periods
        2. **Most Likely Scenario**: Realistic estimate from current average velocity
        3. **Pessimistic Scenario**: Worst-case timeline from lowest velocity periods
        4. **Expected Value**: Weighted calculation = (O + 4√óML + P) √∑ 6
        
        üìä **Mathematical Foundation:**
        ‚Ä¢ Follows beta distribution for project estimation
        ‚Ä¢ Weights most likely scenario 4x more than extremes
        ‚Ä¢ Provides statistically sound forecasts with confidence intervals
        ‚Ä¢ Accounts for both optimism bias and risk factors
        
        üìà **Confidence Intervals:**
        ‚Ä¢ Calculated as ¬±25% of variance between optimistic and pessimistic
        ‚Ä¢ Wider intervals indicate higher uncertainty
        ‚Ä¢ Narrower intervals suggest more predictable delivery patterns
        ‚Ä¢ Use for risk planning and stakeholder communication
        
        üéØ **Practical Application:**
        ‚Ä¢ Expected value: Primary planning target
        ‚Ä¢ Optimistic: Best-case scenario for resource planning
        ‚Ä¢ Pessimistic: Risk mitigation and buffer planning
        ‚Ä¢ Confidence bands: Communication of forecast uncertainty
        
        üí° **Accuracy Factors:**
        Forecast accuracy improves with:
        ‚Ä¢ More historical data points (8+ weeks recommended)
        ‚Ä¢ Consistent team composition and working arrangements
        ‚Ä¢ Stable definition of "done" and point estimation
        ‚Ä¢ Regular, complete data collection practices
    """,
    "weekly_chart_methodology": """
        Weekly velocity charts with predictive forecasting using weighted moving averages.
        
        üìä **Chart Components:**
        ‚Ä¢ Historical bars: Actual weekly completion rates
        ‚Ä¢ Forecast bars: Predicted next week performance using PERT methodology  
        ‚Ä¢ Trend lines: Moving average patterns for visual trend identification
        ‚Ä¢ Confidence intervals: Error bars showing forecast uncertainty ranges
        
        üî¢ **Forecasting Methodology:**
        **Weighted Moving Average:**
        ‚Ä¢ Most recent week: 40% weight
        ‚Ä¢ Second recent: 30% weight  
        ‚Ä¢ Third recent: 20% weight
        ‚Ä¢ Fourth recent: 10% weight
        ‚Ä¢ Formula: 0.4√óW1 + 0.3√óW2 + 0.2√óW3 + 0.1√óW4
        
        **PERT Integration:**
        ‚Ä¢ Optimistic: Top 25% of historical weekly performance
        ‚Ä¢ Most Likely: Weighted moving average calculation
        ‚Ä¢ Pessimistic: Bottom 25% of historical weekly performance
        ‚Ä¢ Expected: (O + 4√óML + P) √∑ 6 for next week prediction
        
        üìà **Visual Interpretation:**
        ‚Ä¢ Solid bars: Confirmed historical performance
        ‚Ä¢ Patterned bars: Forecasted performance with uncertainty
        ‚Ä¢ Error bars: Confidence intervals (¬±25% variance method)
        ‚Ä¢ Trend direction: Overall velocity acceleration or deceleration patterns
        
        üéØ **Usage Guidelines:**
        ‚Ä¢ Use for short-term capacity planning (1-2 weeks ahead)
        ‚Ä¢ Compare forecast vs actual for methodology refinement
        ‚Ä¢ Monitor confidence interval width for prediction reliability
        ‚Ä¢ Adjust team capacity based on consistent trend patterns
    """,
}

# BUG ANALYSIS HELP CONTENT - Tooltips for bug metrics
BUG_ANALYSIS_TOOLTIPS = {
    "resolution_rate": "Percentage of closed bugs. ‚â•80% excellent, 70-79% good, <70% needs attention.",
    "open_bugs": "Current unresolved bug count. Green: 0, Teal: 1-5, Orange: >5 bugs.",
    "expected_resolution": "Forecast weeks to clear bug backlog using last 8 weeks of data. Green: ‚â§2 weeks, Teal: 3-4 weeks, Yellow: >4 weeks.",
}

# Combined comprehensive help content for easy access
COMPREHENSIVE_HELP_CONTENT = {
    "forecast": FORECAST_HELP_DETAILED,
    "velocity": VELOCITY_HELP_DETAILED,
    "scope": SCOPE_HELP_DETAILED,
    "statistics": STATISTICS_HELP_DETAILED,
    "charts": CHART_HELP_DETAILED,
    "bug_analysis": BUG_ANALYSIS_TOOLTIPS,
}
